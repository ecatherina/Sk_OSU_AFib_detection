{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.signal import lfilter, butter, welch\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ecath\\Desktop\\Research\\Raw Data\\LD dataset\\1.csv_annot.csv (10173, 192)\n",
      "C:\\Users\\ecath\\Desktop\\Research\\Raw Data\\LD dataset\\10_Epi.csv_annot.csv (8191, 192)\n",
      "C:\\Users\\ecath\\Desktop\\Research\\Raw Data\\LD dataset\\11_Endo.csv_annot.csv (10173, 192)\n",
      "C:\\Users\\ecath\\Desktop\\Research\\Raw Data\\LD dataset\\12_Epi.csv_annot.csv (10173, 192)\n",
      "C:\\Users\\ecath\\Desktop\\Research\\Raw Data\\LD dataset\\15_Endo.csv_annot.csv (8191, 192)\n",
      "C:\\Users\\ecath\\Desktop\\Research\\Raw Data\\LD dataset\\16_Epi.csv_annot.csv (8191, 192)\n",
      "C:\\Users\\ecath\\Desktop\\Research\\Raw Data\\LD dataset\\17_Endo.csv_annot.csv (10173, 192)\n",
      "C:\\Users\\ecath\\Desktop\\Research\\Raw Data\\LD dataset\\18_Epi.csv_annot.csv (10173, 192)\n",
      "C:\\Users\\ecath\\Desktop\\Research\\Raw Data\\LD dataset\\22.csv_annot.csv (16667, 192)\n",
      "C:\\Users\\ecath\\Desktop\\Research\\Raw Data\\LD dataset\\23.csv_annot.csv (16383, 192)\n",
      "C:\\Users\\ecath\\Desktop\\Research\\Raw Data\\LD dataset\\24.csv_annot.csv (18311, 192)\n",
      "C:\\Users\\ecath\\Desktop\\Research\\Raw Data\\LD dataset\\25.csv_annot.csv (16383, 192)\n",
      "C:\\Users\\ecath\\Desktop\\Research\\Raw Data\\LD dataset\\28.csv_annot.csv (8775, 192)\n",
      "C:\\Users\\ecath\\Desktop\\Research\\Raw Data\\LD dataset\\29.csv_annot.csv (8775, 192)\n",
      "C:\\Users\\ecath\\Desktop\\Research\\Raw Data\\LD dataset\\30.csv_annot.csv (8138, 192)\n",
      "C:\\Users\\ecath\\Desktop\\Research\\Raw Data\\LD dataset\\31.csv_annot.csv (8138, 192)\n",
      "C:\\Users\\ecath\\Desktop\\Research\\Raw Data\\LD dataset\\32.csv_annot.csv (10173, 192)\n",
      "C:\\Users\\ecath\\Desktop\\Research\\Raw Data\\LD dataset\\33.csv_annot.csv (10173, 192)\n",
      "C:\\Users\\ecath\\Desktop\\Research\\Raw Data\\LD dataset\\34.csv_annot.csv (10173, 192)\n",
      "C:\\Users\\ecath\\Desktop\\Research\\Raw Data\\LD dataset\\35.csv_annot.csv (10173, 192)\n",
      "C:\\Users\\ecath\\Desktop\\Research\\Raw Data\\LD dataset\\36.csv_annot.csv (8191, 192)\n",
      "C:\\Users\\ecath\\Desktop\\Research\\Raw Data\\LD dataset\\37.csv_annot.csv (8191, 192)\n",
      "C:\\Users\\ecath\\Desktop\\Research\\Raw Data\\LD dataset\\38.csv_annot.csv (8138, 192)\n",
      "C:\\Users\\ecath\\Desktop\\Research\\Raw Data\\LD dataset\\39.csv_annot.csv (8138, 192)\n",
      "C:\\Users\\ecath\\Desktop\\Research\\Raw Data\\LD dataset\\3_Endo.csv_annot.csv (10173, 192)\n",
      "C:\\Users\\ecath\\Desktop\\Research\\Raw Data\\LD dataset\\4_Epi.csv_annot.csv (10173, 192)\n",
      "C:\\Users\\ecath\\Desktop\\Research\\Raw Data\\LD dataset\\9_Endo.csv_annot.csv (8191, 192)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Uploading data and renaming columns\n",
    "Parameters: \n",
    "-----------\n",
    "path: string\n",
    "    path to the folder with dataframes \n",
    "\n",
    "Returns: \n",
    "-------\n",
    "data_list\n",
    "    List with pd.DataFrames \n",
    "\"\"\"\n",
    "\n",
    "def upload_data(path):\n",
    "\n",
    "    data_list = []\n",
    "    files_list = os.path.join(path, '*.csv')\n",
    "    for filename in glob.glob(files_list):\n",
    "        data = pd.read_csv(filename, header=0)\n",
    "        data.rename(columns=lambda x: x.replace(' ', '_'), inplace=True)\n",
    "        data.rename(columns=lambda x: x.replace('_O', '_opt'), inplace=True)\n",
    "        data.rename(columns=lambda x: x.replace('.', '_opt_'), inplace=True)\n",
    "        data.rename(columns=lambda x: x.replace('Bsk', filename + '_Bsk'), inplace=True)\n",
    "        data.rename(columns=lambda x: x.replace(path, ''), inplace=True)\n",
    "        data.rename(columns=lambda x: x.replace('.csv_annot.csv', ''), inplace=True)\n",
    "        data.rename(columns=lambda x: x.replace('\\\\', ''), inplace=True)\n",
    "        print(filename, data.shape)\n",
    "        data_list.append(data)\n",
    "    return(data_list)\n",
    "path = r'C:\\Users\\ecath\\Desktop\\Research\\Raw Data\\LD dataset'\n",
    "data_list = upload_data(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Division by classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Splitting spreadspeet to the classes by label \n",
    "\n",
    "Parameters: \n",
    "-----------\n",
    "data_list: list\n",
    "    List with pd.DataFrames\n",
    "\n",
    "Returns: \n",
    "-------\n",
    "drivers, nondrivers, noises: list, list, list\n",
    "    Lists with pd.DataFrames, one for each of three classes respectively\n",
    "\"\"\"\n",
    "\n",
    "def class_splitting(data_list):\n",
    "    \n",
    "    drivers = []\n",
    "    nondrivers = []\n",
    "    noises = []\n",
    "\n",
    "    for df in data_list:\n",
    "        driver = pd.DataFrame()\n",
    "        nondriver = pd.DataFrame()\n",
    "        noise = pd.DataFrame()\n",
    "        for col in df.columns[1::3]:\n",
    "            curr_index = list(df.columns).index(col)\n",
    "            prev_index = curr_index - 1\n",
    "            next_index = curr_index + 1\n",
    "            prev_col = df.iloc[:,prev_index]\n",
    "            next_col = df.iloc[:,next_index]\n",
    "            if df[col][0] == 1:\n",
    "                driver[df.columns[prev_index]] = prev_col\n",
    "                driver[df.columns[next_index]] = next_col\n",
    "            elif df[col][0] == 0:\n",
    "                nondriver[df.columns[prev_index]] = prev_col\n",
    "                nondriver[df.columns[next_index]] = next_col\n",
    "            else:\n",
    "                noise[df.columns[prev_index]] = prev_col\n",
    "                noise[df.columns[next_index]] = next_col\n",
    "        drivers.append(driver)\n",
    "        nondrivers.append(nondriver)\n",
    "        noises.append(noise)\n",
    "        \n",
    "    return(drivers, nondrivers, noises)\n",
    "\n",
    "drivers, nondrivers, noises = class_splitting(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make spreadsheet with all siganls \n",
    "\n",
    "# target_d = pd.DataFrame(np.ones((1, drivers.shape[1])), columns=drivers.columns, index=['target'])\n",
    "# drivers = pd.concat([drivers, target_d], axis=0 )\n",
    "\n",
    "# target_nd = pd.DataFrame(np.zeros((1, nondrivers.shape[1])), columns=nondrivers.columns, index=['target'])\n",
    "# nondrivers = pd.concat([nondrivers, target_nd], axis=0)\n",
    "\n",
    "# signals = pd.concat([drivers, nondrivers], axis=1)\n",
    "# signals.fillna(0, inplace=True)\n",
    "# signals.to_csv(r'C:\\Users\\ecath\\Desktop\\Research\\Raw Data\\Raw signals.csv', sep=',', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Butterworth bandpass [1Hz, 20Hz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function performs bandpass filter for the digital signal \n",
    "\n",
    "Parameters: \n",
    "-----------\n",
    "data: array_like\n",
    "    An N-dimensional input array\n",
    "lowcut: float\n",
    "    Low cutoff frequency\n",
    "highcut: float\n",
    "    High cutoff frequency\n",
    "fs: float\n",
    "    Sampling rate of the signal\n",
    "order: int\n",
    "    The order of the filter.\n",
    "\n",
    "Returns: \n",
    "-------\n",
    "filtered_signal: array\n",
    "    The output of the digital filter\n",
    "\"\"\"\n",
    "\n",
    "def butter_bandpass(data, lowcut, highcut, fs, order=2):\n",
    "    nyq = 0.5 * fs\n",
    "    \n",
    "    high = highcut / nyq\n",
    "    low = lowcut / nyq\n",
    "    \n",
    "    b, a = butter(order, [low, high], btype='bandpass', analog=False)\n",
    "    filtered_signal = lfilter(b, a, data)\n",
    "    \n",
    "    return filtered_signal\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Fill NaN with zeros\n",
    "\n",
    "Parameters: \n",
    "-----------\n",
    "df: DataFrame\n",
    "    DataFrame with NaNs\n",
    "    \n",
    "Returns: \n",
    "-------\n",
    "df: Dataframe\n",
    "    All NaNs filled by zeros\n",
    "\"\"\"\n",
    "\n",
    "def del_nul_and_nan(df):\n",
    "    \n",
    "    df.fillna(value=0, axis=1, inplace=True)\n",
    "    \n",
    "################# add to drop off zero columns ######################    \n",
    "#     for col in df.columns:\n",
    "#         if df[col].sum() == 0:\n",
    "#             df.drop([col], axis = 1, inplace = True)  \n",
    "################# add to drop off zero columns ######################    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "Parameters: \n",
    "-----------\n",
    "df: pd.DataFrame\n",
    "    An N-dimensional input DataFrame\n",
    "N: int\n",
    "    Number of sample points\n",
    "lowcut: float\n",
    "    Low cutoff frequency\n",
    "highcut: float\n",
    "    High cutoff frequency\n",
    "fs: float\n",
    "    Sampling rate of the signal\n",
    "\n",
    "Returns: \n",
    "-------\n",
    "fft_out: pd.DataFrame\n",
    "    An output Dataframe with spectrum and frequencies \n",
    "\"\"\"\n",
    "\n",
    "def spec_and_freq_for_single_df_welch(df, N, fs, lowcut, highcut):\n",
    "    \n",
    "    welch_out = pd.DataFrame()\n",
    "    \n",
    "    for col in df.columns:\n",
    "        filtered_yf = butter_bandpass(df[col], lowcut, highcut, fs, order=2)\n",
    "        \n",
    "        welch_xf, welch_yf = welch(filtered_yf, fs=fs, nperseg=len(filtered_yf) / 2, noverlap = len(filtered_yf) / 2.5) #spectrum\n",
    "        \n",
    "        welch_20_index = np.argwhere((welch_xf<25) & (welch_xf>0))        \n",
    "        welch_yf_20 = welch_yf[welch_20_index] #cutting on 20Hz\n",
    "        welch_xf_20 = welch_xf[welch_20_index] #cutting on 20Hz\n",
    "        \n",
    "        welch_yf_20 = pd.DataFrame(welch_yf_20, columns=[col + '_yf'])\n",
    "        welch_xf_20 = pd.DataFrame(welch_xf_20, columns=[col + '_xf']) \n",
    "\n",
    "        welch_out = pd.concat([welch_out, welch_yf_20, welch_xf_20], axis=1)\n",
    "        \n",
    "    return(welch_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Parameters: \n",
    "-----------\n",
    "class_data_list: list\n",
    "    List with DataFrames \n",
    "    \n",
    "Returns: \n",
    "-------\n",
    "all_fft_mem, all_fft_niom: list, list\n",
    "    Dataframes with spectrum and frequencies DataFrames\n",
    "\"\"\"\n",
    "\n",
    "def full_spec_and_freq(class_data_list):\n",
    "    \n",
    "    all_fft_mem = pd.DataFrame()\n",
    "    all_fft_niom = pd.DataFrame()\n",
    "\n",
    "    for k, df in enumerate(class_data_list):\n",
    "\n",
    "        electrode_signal = df[df.columns[::2]]\n",
    "        optical_signal = df[df.columns[1::2]]\n",
    "\n",
    "        electrode_signal = del_nul_and_nan(electrode_signal)\n",
    "        optical_signal = del_nul_and_nan(optical_signal)        \n",
    "        \n",
    "        N = df.shape[0] # Number of sample points\n",
    "        Fs_el = 1017.25 # sampling rate\n",
    "        Fs_om = 1000.0\n",
    "        lowcut = 4\n",
    "        highcut = 20\n",
    "\n",
    "        fft_mem = spec_and_freq_for_single_df_welch(electrode_signal, N, Fs_el, lowcut=lowcut, highcut=highcut)\n",
    "        fft_niom = spec_and_freq_for_single_df_welch(optical_signal, N, Fs_om, lowcut=lowcut, highcut=highcut)\n",
    "\n",
    "        all_fft_mem = pd.concat([all_fft_mem, fft_mem], axis=1)\n",
    "        all_fft_niom = pd.concat([all_fft_niom, fft_niom], axis=1)\n",
    "        \n",
    "    return(all_fft_mem, all_fft_niom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Parameters: \n",
    "-----------\n",
    "class_data_list: list\n",
    "    List with DataFrames \n",
    "label: int, {0,1}\n",
    "    Target label\n",
    "    \n",
    "Returns: \n",
    "-------\n",
    "all_fft_mem, all_fft_niom: DataFrame\n",
    "   Dataframes with added target value\n",
    "\"\"\"\n",
    "\n",
    "def add_target(class_data_list, label):\n",
    "    \n",
    "    all_fft_mem, all_fft_niom = full_spec_and_freq(class_data_list)\n",
    "\n",
    "    all_fft_mem.fillna(value=0, axis=1, inplace=True)\n",
    "    all_fft_niom.fillna(value=0, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    target_mem = np.full(shape=(1, all_fft_mem.shape[1]), fill_value = label)\n",
    "    target_mem = pd.DataFrame(target_mem, columns=all_fft_mem.columns, index=['target'])\n",
    "\n",
    "    target_niom = np.full(shape=(1, all_fft_niom.shape[1]), fill_value = label)\n",
    "    target_niom = pd.DataFrame(target_niom, columns=all_fft_niom.columns, index=['target'])\n",
    "\n",
    "    all_fft_mem = pd.concat([all_fft_mem, target_mem], axis=0)\n",
    "    all_fft_niom = pd.concat([all_fft_niom, target_niom], axis=0)\n",
    "    return(all_fft_mem, all_fft_niom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function that save the Welch spectrumn in .csv format \n",
    "\n",
    "Parameters: \n",
    "-----------\n",
    "path: string\n",
    "    Path where to save file in csv format\n",
    "name_mem: string\n",
    "    Name of the file of MEM spectrum \n",
    "name_niom: string\n",
    "    Name of the file of NIOM spectrum \n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "def spectrum(path, name_mem, name_niom):\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "\n",
    "    driver_spectrum_mem, driver_spectrum_niom  = add_target(drivers, 1)\n",
    "    nondriver_spectrum_mem, nondriver_spectrum_niom = add_target(nondrivers, 0)\n",
    "    noise_spectrum_mem, noise_spectrum_niom = add_target(noises, -1)\n",
    "\n",
    "\n",
    "    full_spectrum_mem = pd.concat([driver_spectrum_mem, nondriver_spectrum_mem, noise_spectrum_mem], axis=1)\n",
    "    full_spectrum_niom = pd.concat([driver_spectrum_niom, nondriver_spectrum_niom, noise_spectrum_niom], axis=1)\n",
    "    \n",
    "    full_spectrum_mem.to_csv(path + name_mem, sep=',', index=True)\n",
    "    full_spectrum_niom.to_csv(path + name_niom, sep=',', index=True)\n",
    "    \n",
    "    return full_spectrum_mem, full_spectrum_niom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ecath\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3790: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "path = r'C:\\Users\\ecath\\Desktop\\Research\\Raw Data\\LD dataset spectrum'\n",
    "mem, niom = spectrum(path, '\\Spectrum of electrode LD Welch.csv', '\\Spectrum of optical LD Welch.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
