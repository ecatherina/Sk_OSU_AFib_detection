{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "from skimage.restoration import denoise_tv_chambolle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\ecath\\Desktop\\Research\\Raw Data'\n",
    "\n",
    "\n",
    "mem_spectrum = pd.read_csv(path + '\\LD dataset spectrum\\Spectrum of electrode LD.csv', index_col=0)\n",
    "niom_spectrum = pd.read_csv(path + '\\LD dataset spectrum\\Spectrum of optical LD.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Scaling of dataframe from 0 to 1 \n",
    "\n",
    "Parameters: \n",
    "-----------\n",
    "df: pd.DataFrame\n",
    "    Dataframe to scale\n",
    "\n",
    "Returns: \n",
    "-------\n",
    "df: pd.DataFrame\n",
    "    Scaled df\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def normalization(df):  \n",
    "        \n",
    "    y_col = [col for col in df.columns if '_yf' in col] \n",
    "    target = pd.DataFrame(df.transpose().target).transpose()\n",
    "    df_ = df.iloc[:-1]\n",
    "    for col in y_col:\n",
    "        df_[col] = (df_[col] - df_[col].min()) / (df_[col].max() - df_[col].min())\n",
    "    df = pd.concat([df_, target], axis=0)\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Split dataframe to driver, nondriver, noise dataframes\n",
    "\n",
    "Parameters: \n",
    "-----------\n",
    "df: pd.DataFrame\n",
    "    Dataframe with all three classes \n",
    "\n",
    "normalize: bool, default False \n",
    "    Scale dataframe or not\n",
    "\n",
    "Returns: \n",
    "-------\n",
    "df, drivers, nondrivers, noises: pd.DataFrame\n",
    "    Original dataframe, driver, nondriver, noise pd.Dataframes\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def make_subdf(df, normalize=False):\n",
    "    \n",
    "    drivers = df.transpose()[df.transpose().target == 1].transpose()\n",
    "    nondrivers = df.transpose()[df.transpose().target == 0].transpose()\n",
    "    noises = df.transpose()[df.transpose().target == -1].transpose()\n",
    "\n",
    "    \n",
    "    if normalize == True: \n",
    "        drivers = normalization(drivers)\n",
    "        nondrivers = normalization(nondrivers)\n",
    "        noises = normalization(noises)\n",
    "        df = normalization(df) \n",
    "    \n",
    "    drivers = drivers.drop(['target'])\n",
    "    nondrivers = nondrivers.drop(['target'])\n",
    "    noises = noises.drop(['target'])\n",
    "    df = df.drop(['target'])\n",
    "    \n",
    "    return(df, drivers, nondrivers, noises)\n",
    "\n",
    "\n",
    "\n",
    "mem_spec, drivers, nondrivers, noises = make_subdf(mem_spectrum, normalize=True)\n",
    "niom_spec, drivers_opt, nondrivers_opt, noises_opt = make_subdf(niom_spectrum, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate the SNR value for MEM and NIOM spectrum\n",
    "\n",
    "Parameters: \n",
    "-----------\n",
    "df: pd.DataFrame\n",
    "    n x m dataframe with spectrums \n",
    "\n",
    "Returns: \n",
    "-------\n",
    "snr: pd.DataFrame\n",
    "    1 x n dataframe with correspondings SNR values\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "def SNR(df):\n",
    "    y_col = [col for col in df.columns if '_yf' in col]\n",
    "    y_df = df[y_col]\n",
    "    snr = []\n",
    "        \n",
    "    for i in range(y_df.shape[1]):          \n",
    "        s = y_df[y_col[i]][y_df[y_col[i]] != 0]\n",
    "        _, properties = find_peaks(s, height=0)\n",
    "        \n",
    "        num_of_avg_peak = 2 #number of highest peak tp average\n",
    "        mean_max = np.mean(np.sort(properties['peak_heights'])[-num_of_avg_peak:]) \n",
    "        \n",
    "        sd = s.std(axis=0)\n",
    "        ratio = np.round(mean_max / sd, 2)\n",
    "        ratio = np.where(sd == 0, 0, ratio)\n",
    "        snr.append(ratio)\n",
    "        \n",
    "    snr = pd.DataFrame(snr, columns=['SNR'], index=y_df.columns)\n",
    "#     snr['SNR'] = (snr['SNR'] - snr['SNR'].min()) / (snr['SNR'].max() - snr['SNR'].min()) #line to rescale SNR value from 0 to 1\n",
    "    return snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SNR(niom_spec).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR(mem_spec).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR(drivers).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR(nondrivers).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR(noises).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
