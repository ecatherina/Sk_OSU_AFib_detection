{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.restoration import denoise_tv_chambolle\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "This notebook generate matrix with features for matricies with Fourier spectrum for electrode and optical mapping. \n",
    "\n",
    "Features description:\n",
    "\n",
    "-  *freq i* - frequency of i$^{th}$ heightest peak\n",
    "-  *height i* - height of i$^{th}$ heightest peak\n",
    "-  *width i* - width of i$^{th}$ heightest peak\n",
    "-  *prominence i* - prominence of i$^{th}$ heightest peak\n",
    "-  *#peaks_th* - number of peaks for given (th) threshhold\n",
    "-  *low_freq_noise* - presence of low-frequency noise (frequency of one of the n highest peaks in the interval from 0 to lf_thHz)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ecath\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3020: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "path = r'C:\\Users\\ecath\\Desktop\\Research\\Raw Data'\n",
    "\n",
    "mem_spectrum = pd.read_csv(path + '\\LD dataset spectrum\\Spectrum of electrode LD.csv', index_col=0)\n",
    "niom_spectrum = pd.read_csv(path + '\\LD dataset spectrum\\Spectrum of optical LD.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(df):  \n",
    "    scaler = StandardScaler() \n",
    "\n",
    "    y_col = [col for col in df.columns if '_yf' in col] \n",
    "\n",
    "    df_yf = df[y_col]\n",
    "    target = pd.DataFrame(df_yf.transpose().target).transpose()\n",
    "    df_yf = df_yf.drop(['target'])\n",
    "    df_yf = df_yf.replace(0, np.nan)\n",
    "\n",
    "    scaled_features = scaler.fit_transform(df_yf.values)\n",
    "    df_ = pd.DataFrame(scaled_features, columns=df_yf.columns, index=df_yf.index)\n",
    "    df_ = df_.fillna(value=0, axis=1)\n",
    "    df_ = pd.concat([df_, target], axis = 0)   \n",
    "    df[y_col] = df_\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ecath\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:776: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "C:\\Users\\ecath\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:781: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  new_unnormalized_variance = np.nanvar(X, axis=0) * new_sample_count\n",
      "C:\\Users\\ecath\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:776: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "C:\\Users\\ecath\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:781: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  new_unnormalized_variance = np.nanvar(X, axis=0) * new_sample_count\n"
     ]
    }
   ],
   "source": [
    "mem_spec = scaling(mem_spectrum)\n",
    "niom_spec = scaling(niom_spectrum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function that generates pd.DataFrame with amount of peaks for (th*100)% threshhold. \n",
    "\n",
    "Parameters: \n",
    "\n",
    "full_df: Dataframe\n",
    "Dataframe with fourier spectrum\n",
    "\n",
    "th: float, from 0 to 1\n",
    "threshhold\n",
    "\n",
    "Returns: \n",
    "\n",
    "features: DataFrame, shape=(full_df[1]/2, 1)\n",
    "number of peaks\n",
    "\"\"\"\n",
    "\n",
    "def number_of_peaks(full_df, th):\n",
    "    all_props = []\n",
    "    df = full_df[full_df.columns[::2]][:-1]\n",
    "    for col in df:\n",
    "        _, properties = find_peaks(df[col][df[col] != 0], height=0)\n",
    "        all_props.append(properties)\n",
    "    num_of_peaks = []\n",
    "    \n",
    "    for i in range(len(all_props)):\n",
    "        try:\n",
    "            max_height = np.max(all_props[i]['peak_heights'])\n",
    "            peaks, _ = find_peaks(df.iloc[:,i], threshold=th)\n",
    "            num = peaks.shape[0]\n",
    "        except ValueError:\n",
    "            num = 0\n",
    "        num_of_peaks.append(num)\n",
    "    num_of_peaks = pd.DataFrame(num_of_peaks, columns=['#peaks_' + str(th)])\n",
    "    return(num_of_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#peaks_2.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1728.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.547454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.925765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        #peaks_2.5\n",
       "count  1728.000000\n",
       "mean      1.547454\n",
       "std       0.925765\n",
       "min       0.000000\n",
       "25%       1.000000\n",
       "50%       1.000000\n",
       "75%       2.000000\n",
       "max       6.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_peaks(mem_spec, 2.5).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_props(full_df):\n",
    "    all_peaks = []\n",
    "    all_props = []\n",
    "\n",
    "    df = full_df[full_df.columns[::2]][:-1]\n",
    "    xf = full_df[full_df.columns[1::2]][:-1]\n",
    "\n",
    "    for col in df:\n",
    "        peaks, properties = find_peaks(df[col][df[col] != 0], height=0, width=0, prominence=0, rel_height=0.5)\n",
    "        all_props.append(properties)\n",
    "        all_peaks.append(peaks)\n",
    "    return df, xf, all_peaks, all_props\n",
    " \n",
    "\n",
    "        \n",
    "def height_width_prominence(full_df, n, prop):\n",
    "    \n",
    "    df, xf, all_peaks, all_props = get_props(full_df)\n",
    "    all_max_prop = []\n",
    "\n",
    "    \n",
    "    for i in range(len(all_props)):\n",
    "        try:\n",
    "            z = np.argsort(all_props[i]['peak_heights'])\n",
    "            z = z[:-(n+1):-1]\n",
    "            \n",
    "            n_max_prop = all_props[i][prop][z] #heights of max peaks\n",
    "            all_max_prop.append(n_max_prop)\n",
    "            \n",
    "        except IndexError:\n",
    "            n_max_prop = np.zeros((n))\n",
    "            all_max_prop.append(n_max_prop)\n",
    "            \n",
    "    all_max_prop = pd.DataFrame(all_max_prop, columns=[prop + ' ' + str(i) for i in range(n)])      \n",
    "    return all_max_prop\n",
    "\n",
    "\n",
    "def freq_and_label(full_df, n):\n",
    "    \n",
    "    df, xf, all_peaks, all_props = get_props(full_df)\n",
    "\n",
    "    freq = []\n",
    "    el_om_labels = []\n",
    "\n",
    "    \n",
    "    for i in range(len(all_props)):\n",
    "        try:\n",
    "            z = np.argsort(all_props[i]['peak_heights'])\n",
    "            z = z[:-(n+1):-1]\n",
    "            \n",
    "            fr = xf.iloc[:,i][all_peaks[i][z]].values #freqs of max peaks\n",
    "            freq.append(fr)\n",
    "            \n",
    "            el_om_label = 1\n",
    "            el_om_labels.append(el_om_label)\n",
    "            \n",
    "        except IndexError:\n",
    "            fr = np.zeros((n))\n",
    "            freq.append(fr)\n",
    "            \n",
    "            el_om_label = 0\n",
    "            el_om_labels.append(el_om_label)\n",
    "    \n",
    "    freq = pd.DataFrame(freq, columns=['freq ' + str(i) for i in range(n)])   \n",
    "    el_om_labels = pd.DataFrame(el_om_labels, columns=['Label for OM and EL'])\n",
    "    return freq, el_om_labels\n",
    "\n",
    "def second_harm(full_df, n): \n",
    "    \n",
    "    df, xf, all_peaks, all_props = get_props(full_df)\n",
    "\n",
    "    \n",
    "    freq = []\n",
    "    given_n = n\n",
    "    \n",
    "    for i in range(len(all_props)):\n",
    "        try:\n",
    "            z = np.argsort(all_props[i]['peak_heights'])\n",
    "            z = z[:-(n+1):-1]\n",
    "            \n",
    "            if len(all_props[i]['peak_heights']) < given_n:\n",
    "                range_n = len(all_props[i]['peak_heights'])\n",
    "            else: \n",
    "                range_n = given_n\n",
    "            \n",
    "            fr_forharm = xf.iloc[:,i][all_peaks[i][z]] # list of frequencies for max peaks\n",
    "            fr_forharm.reset_index(drop = True, inplace = True)\n",
    "\n",
    "            index_forharm = 0 #initiation of second harmonics index (for each i) \n",
    "            for q in range(range_n):\n",
    "                for p in range(range_n):\n",
    "                    try:\n",
    "                        a = fr_forharm[p] / fr_forharm[q] #frequencies relation\n",
    "                        if (a < 2.1) and (a > 1.9): \n",
    "                            index_forharm = 1 # if relation is 2 plus/minus 5% output 1 \n",
    "                    except ZeroDivisionError:\n",
    "                        a = 0 \n",
    "            freq.append(index_forharm)\n",
    "            \n",
    "        except IndexError:\n",
    "            index_forharm = 0\n",
    "            freq.append(index_forharm)\n",
    "    \n",
    "    freq = pd.DataFrame(freq, columns=['second_harmonics'])\n",
    "\n",
    "    return freq\n",
    "\n",
    "\n",
    "def concat(full_df, n):\n",
    "    \n",
    "    height = height_width_prominence(full_df, n, 'peak_heights')\n",
    "    width = height_width_prominence(full_df, n, 'widths')\n",
    "    prominence = height_width_prominence(full_df, n, 'prominences')\n",
    "    freq, label = freq_and_label(full_df, n)\n",
    "    freq_forharm = second_harm(full_df, n) \n",
    "    \n",
    "    features = pd.concat([freq, height, width, prominence, freq_forharm, label], axis=1)\n",
    "    features.fillna(0.0, inplace=True)\n",
    "    return(features)\n",
    "\n",
    "\"\"\"\n",
    "Calculate the SNR value for MEM and NIOM spectrum\n",
    "\n",
    "Parameters: \n",
    "-----------\n",
    "df: pd.DataFrame\n",
    "    n x m dataframe with spectrums \n",
    "\n",
    "Returns: \n",
    "-------\n",
    "snr: pd.DataFrame\n",
    "    1 x n dataframe with correspondings SNR values\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "def SNR(df):\n",
    "    y_col = [col for col in df.columns if '_yf' in col]\n",
    "    y_df = df[y_col]\n",
    "    snr = []\n",
    "        \n",
    "    for i in range(y_df.shape[1]):          \n",
    "        s = y_df[y_col[i]][y_df[y_col[i]] != 0]\n",
    "        _, properties = find_peaks(s, height=0)\n",
    "        \n",
    "        num_of_avg_peak = 2 #number of highest peak tp average\n",
    "        mean_max = np.mean(np.sort(properties['peak_heights'])[-num_of_avg_peak:]) \n",
    "        \n",
    "        sd = s.std(axis=0)\n",
    "        ratio = np.round(mean_max / sd, 2)\n",
    "        ratio = np.where(sd == 0, 0, ratio)\n",
    "        snr.append(ratio)\n",
    "        \n",
    "    snr = pd.DataFrame(snr, columns=['SNR'], index=y_df.columns)\n",
    "#     snr['SNR'] = (snr['SNR'] - snr['SNR'].min()) / (snr['SNR'].max() - snr['SNR'].min()) #line to rescale SNR value from 0 to 1\n",
    "    return snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function that generates final pd.DataFrame with all features\n",
    "\n",
    "Parameters: \n",
    "\n",
    "full_df: Dataframe\n",
    "Dataframe with fourier spectrum\n",
    "\n",
    "n: int\n",
    "number of peaks\n",
    "\n",
    "th1: float, from 0 to 1\n",
    "threshhold\n",
    "\n",
    "th2: float, from 0 to 1\n",
    "threshhold\n",
    "\n",
    "path: str\n",
    "path to save the matrix\n",
    "\n",
    "download: bool\n",
    "download or not download feature matrix\n",
    "\n",
    "Returns: \n",
    "\n",
    "features: DataFrame\n",
    "features for full_df dataframe\n",
    "\"\"\"\n",
    "\n",
    "def create_feature_df(full_df, n, th1, th2, path, name, download=False):    \n",
    "    properties = concat(full_df=full_df, n=n) \n",
    "    num_peak_1 = number_of_peaks(full_df=full_df, th=th1)\n",
    "    num_peak_2 = number_of_peaks(full_df=full_df, th=th2)\n",
    "    snr = SNR(df=full_df)\n",
    "    target = pd.DataFrame(full_df[full_df.columns[::2]].loc['target'].reset_index().drop('index',axis=1))\n",
    "    \n",
    "    features = pd.concat([num_peak_1, num_peak_2, properties, snr, target], axis=1)\n",
    "    \n",
    "    if download == True: \n",
    "        features.to_csv(path + name + '.csv')\n",
    "        return(features)\n",
    "    else:\n",
    "        return(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def electode_optical_matrix(electrode_df, optical_df, path, name, download=False):\n",
    "    electrode_df.drop(['target'], axis=1, inplace=True)\n",
    "    electrode_df.drop(['Label for OM and EL'], axis=1, inplace=True)\n",
    "    el_om_features = pd.concat([electrode_df, optical_df], axis=1)\n",
    "    el_om_features = el_om_features[el_om_features['Label for OM and EL'] == 1]\n",
    "    el_om_features.drop(['Label for OM and EL'], axis=1, inplace=True)\n",
    "    el_om_features = el_om_features.reset_index().drop('index',axis=1)\n",
    "\n",
    "    if download == True: \n",
    "        el_om_features.to_csv(path + name + '.csv', index=False)\n",
    "        return(el_om_features)\n",
    "    else:\n",
    "        return(el_om_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def electode_matrix(electrode_df, path, name, download=False):\n",
    "    electrode_df = electrode_df[electrode_df['Label for OM and EL'] == 1]\n",
    "    electrode_df.drop(['Label for OM and EL'], axis=1, inplace=True)\n",
    "    electrode_df = electrode_df.reset_index().drop('index',axis=1)\n",
    "    \n",
    "    if download == True: \n",
    "        electrode_df.to_csv(path + name + '.csv', index=False)\n",
    "        return(electrode_df)\n",
    "    else:\n",
    "        return(electrode_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_feature_matrices(path, th1, th2, dn_type):\n",
    "    \n",
    "    for i in tqdm_notebook(range(2, 6)):\n",
    "        electrode_df = create_feature_df(mem_spec, n=i, th1=th1, th2=th2, path=path,\\\n",
    "                                         name='\\Feature matrix EL ' + str(i) + ' peaks' + dn_type,  download=True)\n",
    "#         electode_matrix(electrode_df, path=path, name='\\Feature matrix EL short ' + str(i) + ' peaks', download=True)\n",
    "        print(electrode_df.shape)\n",
    "        optical_df = create_feature_df(niom_spec, n=i, th1=th1, th2=th2, path=path,\\\n",
    "                                       name='\\Feature matrix OM ' + str(i) + ' peaks' + dn_type,  download=False)\n",
    "        print(optical_df.shape)\n",
    "        el_om_features = electode_optical_matrix(electrode_df, optical_df,\\\n",
    "                                                 path=path,\\\n",
    "                                                 name='\\Feature matrix EL+OM ' + str(i) + ' peaks' + dn_type,\\\n",
    "                                                 download=True)\n",
    "        print(el_om_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ecb906ba8534f26ad59cbec2f9cd1bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ecath\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\ecath\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\ecath\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\range.py:465: RuntimeWarning: '<' not supported between instances of 'int' and 'str', sort order is undefined for incomparable objects\n",
      "  return self._int64index.union(other)\n",
      "C:\\Users\\ecath\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\api.py:107: RuntimeWarning: '<' not supported between instances of 'str' and 'int', sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3456, 14)\n",
      "(3456, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ecath\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1728, 25)\n",
      "(3456, 18)\n",
      "(3456, 18)\n",
      "(1728, 33)\n",
      "(3456, 22)\n",
      "(3456, 22)\n",
      "(1728, 41)\n",
      "(3456, 26)\n",
      "(3456, 26)\n",
      "(1728, 49)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = r'C:\\Users\\ecath\\Desktop\\Research\\Raw Data\\LD dataset features'\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "download_feature_matrices(path, 2, 3, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
